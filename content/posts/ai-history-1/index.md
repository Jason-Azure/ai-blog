---
title: "AI的70年（上）：从达特茅斯的梦想到漫长的寒冬"
date: 2026-02-24
draft: false
summary: "1956年，十位科学家相信20年就能造出思考的机器。70年后回望，这条路比任何人想象的都要漫长。这是一群异端者的故事——他们在所有人都放弃的年代，选择继续相信。"
categories: ["AI 基础"]
tags: ["AI历史", "神经网络", "RNN", "深度学习", "AI寒冬"]
weight: 11
ShowToc: true
TocOpen: true
---

## 序：2022年11月30日，一声惊雷

2022年11月30日，旧金山，一个普通的星期三。

OpenAI悄悄上线了一个对话程序。没有发布会，没有广告投放，只有一条推文和一个网页链接。

五天后，用户破百万。两个月后，月活用户过亿——这是人类历史上增长最快的消费产品。TikTok用了9个月达到这个数字，Instagram用了两年半。

ChatGPT像一颗炸弹落入平静的湖面。全世界突然意识到：**机器，好像真的可以思考了。**

但如果你往回追溯——越过GPT-3的1750亿参数，越过2017年那篇改变一切的论文，越过深度学习的两次寒冬，越过那些在黑暗中独行的研究者——你会发现，这不是横空出世。

这是一条70年的长路。

而这条路上最惊心动魄的，不是那些改变世界的论文，而是那些在所有人都放弃的年代，选择继续相信的人。

---

## 本文导读

本系列共三篇，沿着一条时间线展开——**从最初的梦想，到最深的低谷，再到最终的爆发。**

<div style="max-width: 620px; margin: 1.5em auto; font-size: 0.93em; line-height: 1.9;">

<div style="border-left: 3px solid #4CAF50; padding-left: 14px; margin-bottom: 10px;">
<strong>上篇：梦想与寒冬（1943—2006）← 本文</strong><br>
<span style="color: #888;">达特茅斯的夏天 → 赋予机器记忆 → 两次AI寒冬 → 黎明前的坚守</span><br>
从"人工智能"这个词的诞生，到三十年无人问津的至暗时刻。
</div>

<div style="border-left: 3px solid #2196F3; padding-left: 14px; margin-bottom: 10px;">
<strong>中篇：复兴与爆发（2009—2022）</strong><br>
<span style="color: #888;">GPU革命 → AlexNet转折点 → Transformer → GPT四级跳 → ChatGPT</span><br>
两块游戏显卡如何改写历史，以及"注意力就是一切"为什么是AI的最重要发现。
</div>

<div style="border-left: 3px solid #FF9800; padding-left: 14px;">
<strong>下篇：争鸣与未来</strong><br>
<span style="color: #888;">AI到底缺什么 → 反对派的深层批判 → 对齐与觉醒 → 当造物审视造物主</span><br>
最有分量的质疑者们在担心什么？而70年AI之路给我们最深的启示是什么？
</div>

</div>

---

## 第一章：播种——那些疯狂的先驱者（1943—1957）

### 一切始于一篇数学论文

1943年，第二次世界大战的炮火还在欧洲燃烧。

在芝加哥大学，神经科学家 **Warren McCulloch** 和数学家 **Walter Pitts** 发表了一篇论文：《A Logical Calculus of the Ideas Immanent in Nervous Activity》。标题拗口，意思却很直白——**他们用数学公式描述了一个人工神经元。**

这个"神经元"极其简单：接收几个输入信号，加权求和，如果总和超过一个阈值，就输出1；否则输出0。

没有人把它太当回事。但回头看，这是人类第一次用数学语言说：**大脑的思维过程，也许可以用计算来模拟。**

> **论文卡片**
> McCulloch & Pitts (1943), *A Logical Calculus of the Ideas Immanent in Nervous Activity*, Bulletin of Mathematical Biophysics
> **一句话意义：** 人工神经元的数学模型——人类第一次把"思考"写成了方程。

### 图灵的追问

1950年，英国曼彻斯特。

Alan Turing——破解了纳粹密码机Enigma、奠定了现代计算机理论的天才——发表了一篇日后被引用无数次的论文：《Computing Machinery and Intelligence》。

论文的开头只有一句话：

> *"I propose to consider the question, 'Can machines think?'"*
> "我想讨论一个问题：机器能思考吗？"

Turing没有直接回答，而是提出了一个替代方案——后来被称为**"图灵测试"**：如果你和一台机器进行文字对话，无法分辨对方是人还是机器，那么我们就可以说这台机器在"思考"。

这个标准在70年后依然是AI领域最著名的思想实验。ChatGPT在2023年的表现，让无数人第一次真正感受到了图灵测试的重量。

> **论文卡片**
> Alan Turing (1950), *Computing Machinery and Intelligence*, Mind
> **一句话意义：** 提出图灵测试——"如果你分不清它是不是在思考，那它就是在思考。"

### 达特茅斯的夏天：AI得名

1956年夏天，美国新罕布什尔州，达特茅斯学院。

一个年轻的数学家 **John McCarthy** 说服了洛克菲勒基金会，资助了一场为期两个月的研讨会。他邀请了十位当时最聪明的人，包括信息论之父 **Claude Shannon**、认知科学先驱 **Marvin Minsky**、IBM的 **Nathaniel Rochester**，以及后来发明LISP语言的McCarthy本人。

McCarthy在申请书上写道：

> *"We propose that a 2-month, 10-man study of artificial intelligence be carried out... The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it."*

这段话翻译过来就是：

**"学习的每一个方面，智能的每一个特征，原则上都可以被精确描述，从而制造一台机器来模拟它。我们建议用两个月来研究这个问题。"**

两个月。他们以为两个月就能取得突破性进展。

这是"人工智能"（Artificial Intelligence）这个词第一次被正式使用。从那个夏天算起，到2026年的今天——**AI研究已经走过了整整70年。**

现实证明，McCarthy低估了这个问题的难度。低估了大约三十五倍。

> **历史坐标**
> 1956年达特茅斯会议（Dartmouth Conference）
> **参会者：** John McCarthy, Marvin Minsky, Claude Shannon, Nathaniel Rochester 等10人
> **历史意义：** "Artificial Intelligence"一词诞生。与会者乐观预测"20年内"可解决智能问题。
> **残酷现实：** 70年后的今天，我们仍在争论机器是否真的在"思考"。

### 感知机：第一道曙光

达特茅斯会议之后的第二年，1957年，**Frank Rosenblatt** 在康奈尔大学造出了**感知机（Perceptron）**——第一个可以通过数据学习的神经网络。

感知机能做什么？它能学会区分简单的图形模式，比如把三角形和正方形分开。

美国海军大为兴奋，给了Rosenblatt大量资助。媒体更是疯狂——《纽约时报》报道说，这台机器"将能走路、说话、看东西、写字，甚至能自我复制、感知自身的存在"。

1957年的人们真诚地相信，真正的人工智能近在咫尺。

他们不知道的是，一场漫长的寒冬即将到来。

---

## 第二章：第一次寒冬——一本书如何杀死一个领域（1969—1980s）

### Minsky的致命一击

1969年，Marvin Minsky和Seymour Papert出版了一本书：**《Perceptrons》**。

讽刺的是，Minsky本人也是达特茅斯会议的参加者之一——他曾经也是AI的信徒。但在这本书里，他用严格的数学证明指出了感知机的致命缺陷：**单层感知机无法解决XOR（异或）问题。**

XOR是什么？这是一个简单得令人尴尬的逻辑问题：

```text
输入A  输入B  →  输出
 0      0    →   0
 0      1    →   1
 1      0    →   1
 1      1    →   0
```

就是"两个输入不同时输出1，相同时输出0"。一个小学生都能理解的规则，感知机却学不会。

Minsky的证明是正确的——对于**单层**感知机而言。但问题在于，他的表述方式让整个学术界得出了一个远超他本意的结论：**神经网络是死路一条。**

这本书的杀伤力是毁灭性的。

美国国防高级研究计划局（DARPA）大幅削减了神经网络研究的经费。英国政府在Lighthill报告的影响下，几乎完全停止了AI领域的资助。学术界的风向瞬间逆转——**研究神经网络的人从先驱变成了异端。**

一位年轻的英国研究者后来回忆说：

> "在那个年代，如果你说你研究神经网络，人们会觉得你不是疯了，就是蠢。更可能两者兼有。"

这个年轻人叫 **Geoffrey Hinton**。他的故事，我们后面会讲。

### 符号AI的统治

《Perceptrons》之后，**符号AI（Symbolic AI）** 成为主流。这种方法认为，智能的本质是**逻辑推理和规则运算**——只需要把人类的知识编码成"如果...那么..."的规则，机器就能变得智能。

1980年代，这种思路催生了"专家系统"热潮。日本政府投入近9亿美元启动了"第五代计算机"计划，目标是造出能够自主推理的计算机。各大公司纷纷投入重金开发专家系统。

但专家系统很快暴露了致命问题：

- **知识瓶颈**：每条规则都需要人类专家手工编写。一个医疗诊断系统可能需要上万条规则，而且规则之间经常矛盾
- **脆弱性**：面对规则库之外的情况，系统彻底懵圈，连"这个我不知道"都说不出来
- **无法学习**：这些系统不会从经验中成长，永远只能做被明确编程的事

到了1980年代末，专家系统的泡沫破裂。日本的"第五代"计划以失败告终。AI迎来了**第二次寒冬。**

---

## 第三章：暗流——寒冬中的播种者（1986—1997）

寒冬并不意味着所有人都停下了脚步。

恰恰相反，AI历史上最重要的几项发明，都诞生在这段"无人关注"的年代。就像种子在冰雪下悄悄萌发，等待春天。

### 反向传播：多层网络学会了训练自己（1986）

1986年，三位研究者发表了一篇论文，解决了一个困扰神经网络领域十几年的核心问题：**多层神经网络怎么训练？**

**David Rumelhart、Geoffrey Hinton 和 Ronald Williams** 在 Nature 杂志上发表了《Learning representations by back-propagating errors》，提出了**反向传播算法（Backpropagation）**。

核心思路说起来很直觉：网络的输出和正确答案之间有个差距（误差），把这个误差**反向传播**回去——从输出层到隐藏层到输入层——沿途调整每一层的权重，让误差一点点缩小。

这个想法的数学基础其实很优雅：**链式求导法则**。你在高中数学里学过的那个东西，被用来训练拥有数百万参数的神经网络。

反向传播的意义在于：Minsky证明了单层感知机不行，但**多层网络可以解决XOR**，甚至可以学会远比XOR复杂得多的任务。反向传播给出了训练这些多层网络的方法。

**从这一刻起，深度学习的数学基石已经就位。缺的只是数据和算力。**

> **论文卡片**
> Rumelhart, Hinton & Williams (1986), *Learning representations by back-propagating errors*, Nature
> **一句话意义：** 反向传播算法——教会了多层神经网络"从错误中学习"，是后来一切深度学习的训练基石。

### 赋予机器记忆：Jordan的循环网络（1986）

同一年，另一位名叫 Michael Jordan 的研究者（不是打篮球的那位）提出了一个更基本的问题：**怎么让网络拥有"记忆"？**

传统的神经网络是"无状态"的——给它一张图片，它输出一个分类，然后就全忘了。但人类的思维是有**连续性**的：你读一个句子时，读到第五个字的时候还记得前四个字说了什么。

Jordan引入了**状态单元（State Units）**——一种特殊的设计，把网络上一时刻的输出反馈回输入端。这样，网络在处理当前输入时，能"看到"自己之前做了什么。

这就是**循环神经网络（RNN）** 的雏形。

更有趣的是，Jordan发现了**吸引子（Attractor）** 现象：当你从一个训练数据中没有出现过的新坐标启动网络，它会自动修正回到已学会的稳定轨迹上。**这意味着网络不是在死记硬背，而是学会了轨迹的几何特征——它在泛化。**

### Elman的50个神经元：语言的秘密（1991）

1991年，Jeffrey Elman在Jordan的基础上做了一个惊人的实验。

他用一个只有**50个神经元**的微型网络来处理连续的英文字母流——没有空格，没有标点，没有任何词语边界的标记。网络的任务只有一个：**预测下一个字母是什么。**

然后，奇迹发生了。

Elman观察到，网络的预测误差呈现出一种明确的节奏——

- **当一个新单词开始时**，误差突然飙升（因为网络不知道新词的第一个字母是什么）
- **随着单词内部字母推进**，误差逐渐降低（一旦看到"t-h-e"的"t-h"，下一个字母几乎可以确定是"e"）
- **到达词语边界时**，误差再次跳升

这种误差的"波峰-波谷"节奏，就是信息论中的**熵（Entropy）** 的变化。网络通过"熵的涨落"，**自发发现了词语的边界**——从来没有人告诉它什么是"单词"。

但更惊人的发现在隐藏层里。Elman探测网络内部的神经元活动，发现它自动形成了**分层的语义聚类**：

```text
所有词汇
├── 有生命的
│   ├── 人类 (man, woman, boy, girl...)
│   └── 动物 (cat, dog, mouse...)
└── 无生命的
    ├── 可食用 (cookie, bread, food...)
    └── 易碎品 (glass, plate, cup...)
```

**50个神经元，仅仅通过"预测下一个字母"这一个任务，就自发涌现出了对世界的分类理解。**

这个发现直接挑战了语言学家 **Noam Chomsky** 的核心观点。Chomsky坚持认为，人类语言能力的复杂性决定了它必须是先天的——写在基因里的"语言习得装置"。而Elman证明了：**复杂的语义理解完全可以从统计模式的预测中自发涌现。**

如果你觉得这个结论似曾相识——没错，三十年后，GPT系列大模型的核心设计哲学，就是这五个字：

**预测下一个词。**

> **论文卡片**
> Elman, J.L. (1991), *Finding Structure in Time*, Cognitive Science
> **一句话意义：** 50个神经元证明了"预测下一个符号"就能涌现出语法和语义理解——这个理念在30年后成为GPT的核心设计哲学。

### LSTM：记住该记住的，忘掉该忘掉的（1997）

Jordan和Elman的循环网络有一个致命问题：**记忆会衰减。**

假设你在读一篇小说，第一页提到"主角叫李明"，到了第一百页写到"他走进了房间"——"他"指的是谁？人类可以毫不犹豫地回答"李明"。但RNN不行。

原因是技术性的，叫做**梯度消失（Vanishing Gradient）**：当反向传播跨越很多时间步时，梯度会像连乘一串小于1的数一样，越乘越小，最终趋近于零。这意味着**网络对很久以前的信息几乎完全"失忆"。**

1997年，在德国慕尼黑，**Sepp Hochreiter** 和 **Jürgen Schmidhuber** 提出了解决方案：**LSTM（Long Short-Term Memory，长短期记忆网络）**。

LSTM的核心创新是引入了三个"**门（Gate）**"：

- **遗忘门**：决定丢弃哪些过时信息（"场景已经换了，丢掉上一个场景的细节"）
- **输入门**：决定记住哪些新信息（"新出现了一个重要角色，记住这个名字"）
- **输出门**：决定输出哪些信息（"当前问的是谁走进了房间，输出角色名"）

这三个门让网络可以**选择性地记忆和遗忘**，从而保持对长距离信息的追踪。

但这里有一个令人唏嘘的事实：**LSTM发表于1997年，几乎无人问津。** Hochreiter和Schmidhuber在之后的近十五年里，不断推广这项技术，屡屡碰壁。

直到2012年之后深度学习爆发，LSTM才突然成为语音识别、机器翻译、自然语言处理的标配架构——Google翻译、Siri的语音识别，背后都是LSTM。

**超前十五年。这就是寒冬中播种的代价。**

> **论文卡片**
> Hochreiter & Schmidhuber (1997), *Long Short-Term Memory*, Neural Computation
> **一句话意义：** 用"门控"机制解决RNN的梯度消失问题，让网络第一次拥有了可靠的长期记忆。发表时无人关注，15年后成为标配。

---

## 第四章：至暗时刻——第二次AI寒冬（1990s—2000s）

如果说第一次AI寒冬是一场暴风雪，那第二次AI寒冬更像是一场漫长的、看不到尽头的阴天。没有戏剧性的转折，只有持续的、令人窒息的冷漠。

### "你为什么还在研究这个？"

1990年代到2000年代初期，机器学习领域被**支持向量机（SVM）**、**随机森林**、**核方法**等"浅层"方法统治。这些方法有数学上的优雅证明，在小数据集上表现良好，而且——最重要的——不需要GPU，不需要大量数据，不需要等好几天才能训练完。

神经网络？太慢、太贵、太不可靠、太没有理论支撑。

当时的学术界有一种普遍的鄙视链：研究神经网络的论文很难被顶级会议接收。NIPS（现在改名叫NeurIPS）会议上提交神经网络的论文，评审意见经常就一句话：**"This is just a neural network."** ——言下之意，不值得讨论。

Hinton后来回忆说：

> "我们就像一小群人在沙漠中行走，所有人都说前面没有绿洲。我们也不确定，但我们没有回头路了。"

### 一个叫Hinton的固执老头

如果这个故事有一个主角，那一定是 **Geoffrey Hinton**。

Hinton1947年出生于英国伦敦，曾祖父是布尔代数的发明者 George Boole（是的，编程语言里的"Boolean"就是他家的）。他原本学的是实验心理学，后来转向人工智能，在爱丁堡大学拿到了AI的博士学位。

从1970年代开始，Hinton就坚定地相信一件事：**人类的智能来源于神经元之间连接权重的调整，而不是逻辑规则的运算。** 这在当时是彻底的异端邪说。

他的学术生涯几乎就是一部"逆流而上"的编年史：

| 年代 | Hinton在做什么 | 主流学术界在做什么 |
|------|--------------|------------------|
| 1970s | 研究神经网络的学习算法 | 认为神经网络已死 |
| 1980s | 参与发明反向传播 | 热炒专家系统 |
| 1990s | 探索深度网络的训练方法 | 推崇SVM和核方法 |
| 2000s | 发明深度信念网络 | "Neural networks? Seriously?" |

在加拿大多伦多大学（他因为反对里根政府的军事研究而离开了美国），Hinton带着极少的经费和屈指可数的学生，一年又一年地发论文，一年又一年地被主流无视。

然后，在2006年，他发出了一声信号弹。

### 2006：复兴宣言

2006年，Hinton发表了一篇论文：《A Fast Learning Algorithm for Deep Belief Nets》。

核心观点：**深层神经网络可以被有效训练。**

此前学术界的共识是：超过两三层的网络根本训不动——梯度消失会让深层的权重纹丝不动。Hinton的突破在于引入了"逐层预训练"的技巧：先用无监督学习一层一层地初始化网络，再用反向传播做微调。

这篇论文的实验规模很小——受限于当时的硬件，只能在MNIST手写数字识别这样的小数据集上验证。但它传递了一个明确的信号：

**深度网络不是死路。走得更深，可能走得更远。**

学术界开始有人侧耳倾听了。但真正的爆发，还需要再等六年——等待硬件革命的到来。

> **论文卡片**
> Hinton, Osindero & Teh (2006), *A Fast Learning Algorithm for Deep Belief Nets*, Neural Computation
> **一句话意义：** 深度学习的"复兴宣言"——证明了深层网络可以被有效训练，终结了"网络不能太深"的学术偏见。

### 三巨头与图灵奖

这里需要介绍另外两位在寒冬中坚持的人。

**Yann LeCun**，法国人，1980年代在Hinton指导下学习反向传播，后来发明了**卷积神经网络（CNN）**。1998年，他的LeNet-5被AT&T用来识别支票上的手写数字——这可能是神经网络在寒冬中最成功的商业应用。但他在学术界同样长期被边缘化，直到2013年加入Facebook（现Meta）担任首席AI科学家。

**Yoshua Bengio**，加拿大蒙特利尔大学教授，在深度学习最低谷的时期仍然坚持研究神经网络的学习表示。他培养了大量深度学习人才，被称为"蒙特利尔学派"的灵魂人物。

2018年，Hinton、LeCun和Bengio三人共同获得了**图灵奖**——计算机科学的最高荣誉，被称为"计算机界的诺贝尔奖"。

颁奖词说他们"使深度神经网络成为了计算的关键组成部分"。

但更准确的说法也许是：**他们在整个世界都说"不行"的时候，坚持说"可以"——然后用三十年证明了自己。**

<div style="border-left: 3px solid #9C27B0; padding: 12px 14px; margin: 1.5em 0; font-size: 0.95em; line-height: 1.8;">

**深度学习三巨头**

| 人物 | 国籍 | 主要贡献 | 坚持年代 |
|------|------|---------|---------|
| Geoffrey Hinton | 英国/加拿大 | 反向传播、深度信念网络、AlexNet指导者 | 1970s—至今 |
| Yann LeCun | 法国/美国 | 卷积神经网络(CNN)、LeNet | 1980s—至今 |
| Yoshua Bengio | 加拿大 | 深度学习理论、蒙特利尔学派 | 1990s—至今 |

**2018年共获图灵奖。** 从边缘到最高荣誉，他们等了三十年。

</div>

---

## 第五章："智能即压缩"——一个超前十年的预言（2011）

2011年，在神经网络研究者还在被主流学术界白眼的时候，一个极具远见的理论被提出：

> **文本压缩等同于智能。**

这个观点认为，大脑本质上是一台**预测机器**。所谓"学习"，就是把海量的经验信息压缩进一个可预测的世界模型中。如果你能完美地预测一段文本的下一个词，那意味着你**理解**了这段文本背后的一切——语法、语义、常识、逻辑、甚至世界运行的规律。

为了验证这个理论，研究者训练了一个拥有数百万连接的大型网络，然后给了它一个提示：

> **"The meaning of life is..."**（"生命的意义是..."）

网络的回答是：

> *"The tradition of the ancient human reproduction."*（"古代人类生殖的传统。"）

听起来荒诞不经。而且网络在说了几句之后就开始胡言乱语。

但研究者在论文末尾写下了一段大胆的预言：

> **如果能将网络规模提升至数亿神经元和数十亿连接，单纯依靠算力的"暴力破解"可能产生出超乎想象的高性能。**

2011年没有人认真对待这句话。2020年GPT-3的1750亿参数证明了它的先见之明。

这就是后来被称为**"暴力美学（Brute Force Aesthetics）"** 和 **"Scaling Law"** 的理论雏形——不需要设计更聪明的算法，只需要把模型做得更大、数据灌得更多、算力堆得更猛。

**简单，粗暴，有效。**

---

## 本篇小结：暗夜中的星光

让我们回望这段从1943年到2000年代末的历史：

**时间线一览：**

| 年份 | 事件 | 情感色调 |
|------|------|---------|
| 1943 | McCulloch & Pitts提出人工神经元 | 🌱 萌芽 |
| 1950 | 图灵提出"机器能思考吗？" | 💡 设问 |
| 1956 | 达特茅斯会议，AI得名 | ☀️ 乐观 |
| 1957 | Rosenblatt发明感知机 | 🔥 狂热 |
| 1969 | Minsky《Perceptrons》出版 | ❄️ 寒冬降临 |
| 1986 | 反向传播 + Jordan的RNN | 🌱 暗流涌动 |
| 1991 | Elman的50个神经元实验 | ✨ 低调的惊人发现 |
| 1997 | LSTM发表，无人关注 | 😔 超前的孤独 |
| 2006 | Hinton的深度信念网络 | 🔔 复兴的信号弹 |
| 2011 | "智能即压缩"理论 | 🔮 超前的预言 |

从1969年到2012年，超过四十年，神经网络研究者们在学术界的边缘生存。他们的论文被拒绝，经费被削减，同行嘲笑他们是"不切实际的幻想家"。

但正是在这段无人关注的时期，最关键的技术积淀悄悄完成了：

- **反向传播**给出了训练的方法
- **RNN/LSTM**赋予了网络记忆
- **"预测下一个词"**的哲学被验证
- **"暴力扩大规模"**的直觉被提出

所有的弹药都已就位。**缺的只是一根导火索。**

这根导火索，来自一个意想不到的地方——2012年多伦多大学一间狭小的实验室里，**两块游戏显卡**。

**中篇预告：** 2012年的AlexNet如何用GPU改写历史？为什么"注意力就是一切"？1750亿参数的GPT-3到底学会了什么？敬请期待：[《AI的70年（中）：从两块显卡到改变世界的注意力机制》](/ai-blog/posts/ai-history-2/)

---

<div style="text-align: center; color: #888; font-size: 0.9em; margin-top: 2em;">

博客：[AI-lab学习笔记](https://Jason-Azure.github.io/ai-blog/) ｜ 微信公众号：AI-lab学习笔记

</div>
